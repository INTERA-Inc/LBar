{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import .xlsx file, concatenate datasets from two stations (MW3, MW4), qa-check, export new file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and create the two station/well transducer datasets, dataframes**\n",
    "\n",
    "*You will be prompted to enter the file pathway & extension for the MW-3/MW-4 datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Two Wells w/ hobo's: MW-3, MW-4\n",
    "#load each dataset per well, then add column 'station' == 'MW-3' or 'MW-4'\n",
    "\n",
    "print(\"example file path: S\\AUS\\....Transducer Data\\Exports\\20804187_MW-3 2021-03-31 08_03_57 -0600.xlsx\")\n",
    "      \n",
    "MW3_df = pd.read_excel(input(str(\"Enter MW-3 transducer data path, file, extension: \")), sheet_name=\"DATA\", header=1)\n",
    "MW3_df = MW3_df.resample('d', on ='Date Time, GMT -0600').mean().reset_index()\n",
    "MW3_df['station'] = 'MW-3'\n",
    "\n",
    "MW4_df = pd.read_excel(input(str(\"Enter MW-4 transducer data path, file, extension: \")), sheet_name=\"DATA\", header=1)\n",
    "MW4_df = MW4_df.resample('d', on ='Date Time, GMT -0600').mean().reset_index()\n",
    "MW4_df['station'] = 'MW-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code should load MW3, MW4; resample on day and provide the mean values;\n",
    "#The code should add a column 'station'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate the two dataframes vertically: MW3_df, MW4_df**\n",
    "\n",
    "*Run check to see if dataframes concatenated correctly*\n",
    "\n",
    "*inspect the new dataframe .head()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenate the two above dataframes\n",
    "df_concat = pd.concat([MW3_df, MW4_df])\n",
    "print(\"concat dataframe shape: \" + str(df_concat.shape))\n",
    "\n",
    "#Concatenation QA check\n",
    "if len(df_concat) == (len(MW3_df) + len(MW4_df)):\n",
    "    print(\"New dataframe shape concatenated vertically OK\")\n",
    "else:\n",
    "    print(\"Check previous code; dataframe shape incorrect\")\n",
    "    \n",
    "#inspect new dataframe\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to format and build a new dataframe \"df\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to format, create new, final dataframe\n",
    "def formatting():\n",
    "    \n",
    "    datetime = pd.to_datetime(pd.Series(df_concat['Date Time, GMT -0600']).rename('datetime'), format = '%YYYY-%mm-%dd %HH:%mm')\n",
    "    station = pd.Series(df_concat['station']).rename('station')\n",
    "    AbsPress = pd.Series(df_concat['Abs Press, psi']).rename('Abs Press')\n",
    "    BaroPress = pd.Series(df_concat['Baro Press, psi']).rename('Baro Press')\n",
    "    DiffPress = pd.Series(df_concat['Diff Press, psi']).rename('Diff Press')\n",
    "    \n",
    "    data = {'datetime': datetime,\n",
    "           'station': station,\n",
    "           'Abs Press': AbsPress,\n",
    "           'Baro Press': BaroPress,\n",
    "           'Diff Press': DiffPress}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = formatting()\n",
    "\n",
    "print(df.head())\n",
    "print(\"  \")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical description of df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for NaN/Null Values in df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes for the next steps**\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the concatenated dataframe as .xlsx to filepath\n",
    "def export():\n",
    "    df.to_excel(input(str(\"Enter the export file path and extension: \")), index=False)\n",
    "\n",
    "export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
